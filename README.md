# Alice AI

Inspired by Maid-chan from Sakurasou no Pet na Kanojo

## セットアップ

### 1. 仮想環境の作成と有効化
```bash
python -m venv venvAlice
venvAlice\Scripts\activate
pip install -r requirements.txt
```

### 2. 環境設定
```bash
copy .env.example .env
# .env を編集してAPIキーを設定
```

#### ローカルモデルを使う場合（任意）
- `.env` で `AI_BACKEND=ollama` / `local` / `auto` を設定
- `LOCAL_MODEL_REPO` / `LOCAL_MODEL_FILE` は `auto` 推奨（PCスペックに応じて自動選択）
- 起動時に Hugging Face から GGUF をダウンロードして利用
- 既定値は TinyLlama GGUF（`TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF`）
- Ollama を使う場合は Ollama 本体をインストールして `OLLAMA_URL` を設定

### 3. キャラクター画像の配置
```
assets/images/alice_default.png   ... 全身立ち絵（必須）
```

> **注意**: `assets/images/` に PNG ファイルを直接配置してください。  
> 画像は `1:1` の正方形（推奨: 512×512 以上）、背景透過（RGBA）が最適です。

### 4. 起動
```bash
python AliceApp.py
```

### 5. 音声入力（任意）
```bash
pip install SpeechRecognition pyaudio
```
- 入力欄の `音声入力` ボタンでマイク音声をテキスト化して入力欄へ反映
- `Ctrl+Enter` または `送信` ボタンで送信

## ディレクトリ構成

```
AliceApp/
├─ AliceApp.py               # エントリポイント（起動制御・実行シーケンス管理）
├─ .env                      # 環境設定（Git管理外）
├─ .env.example              # 設定テンプレート
├─ requirements.txt
│
├─ module/                   # 外装モジュール（物理操作担当）
│   ├─ env_binder_module.py         # .env 読み込み・設定値提供
│   ├─ neural_loader_module.py      # Gemini クライアントロード・検証
│   ├─ prompt_shaper_module.py      # ペイロード構築・Message 型定義
│   ├─ result_log_module.py         # 履歴永続化（JSON）・コンソール出力
│   ├─ display_mode_module.py       # テーマ・レイアウト・アニメーション定義
│   └─ window_module.py             # メインウィンドウ・各ダイアログ
│
└─ src/
    └─ AI/
        └─ heart.py          # AI推論の心臓部（中層構造・外部依存なし）
```

## 設計原則

- AIロジックの完全隔離（`src/AI/heart.py`）
- 単方向データフロー（逆流禁止）
- モジュール責務の厳格分離
- 環境変数は `env_binder_module` 経由でのみ取得
- 外装モジュールは末尾に `_module` を必ず付与

## 責務分離マトリクス

| モジュール               | 物理処理 | 設定参照 | 推論 | 永続化 |
|--------------------------|----------|----------|------|--------|
| module/                  | ○        | ○        | ×    | ○      |
| src/AI/heart.py          | ×        | ×        | ○    | ×      |
| AliceApp.py              | 制御のみ | ×        | ×    | ×      |

## Git運用

- ブランチは常に `testbranch` を使用
- commit は GUI メニュー → Git から実行可能
- push（sync）はユーザーが手動で実行

## 未実装
## クロスプラットフォーム対応未実装
- 各プラットフォーム事のアプリ化

## AIキャラクターのアニメーション化
- GUI上またはアプリ上でキャラクター動き、話、ユーザとコミニュケーションを取る機能が不完全。
- 現状ではキャラクターではなく画像に対してアニメーションが付与されている。

## 更新履歴
- 2026-03-01 04:06:10 JST
  - 入力欄未表示の再発対策として、チャット領域を縦分割（履歴/入力）Paneに変更し、入力ブロックの最低高さを常時確保する実装へ修正
  - 設定画面に `AI_BACKEND=ollama` と `OLLAMA_URL` / `OLLAMA_MODEL_NAME` の設定項目を追加
  - `module/ollama_hf_loader_module.py` を追加し、PCスペックに応じてHFの無料GGUFを選択→ダウンロード→Ollamaモデル作成/利用する処理を実装
  - `src/AI/ollama_heart.py` を追加し、Ollama API経由のチャット推論（ストリーム対応）を実装
  - AI設定変更時は自動再起動して新モデルを反映する処理を追加し、起動時ポップアップで切替モデルを通知する挙動に対応
- 2026-03-01 03:47:58 JST
  - `README.md` の更新履歴と現行実装を突合し、未実装だった「音声入力→入力欄反映」「Ctrl+Enter送信」を実装
  - チャットUIを「履歴ブロック」と「入力ブロック」に分離し、履歴はスクロール、入力欄は常時表示される構造へ修正
  - 入力欄の `音声入力` ボタンでマイク音声を文字起こしし、入力欄へ追記する処理を追加
  - 既存の読み上げ制御は `読上` ボタンとして分離し、既存コードを削除せず機能追加
  - 音声入力依存として `SpeechRecognition` を requirements に追記
- 2026-03-01 03:35:58 JST
  - 起動時フラッシュの原因だった「起動直後のレイアウト再適用連打」を撤去し、軽量な1回チェック方式に変更
  - チャットUIの初期構築順を見直し、入力欄を先に下部へ配置した上で履歴表示をその上に配置するよう修正
  - 入力コンテナ高さが潰れた場合の自動復旧処理を追加し、入力欄・送信ボタン・音声ボタンが消えないよう改善
  - 起動ポップアップ終了後は不要な全体レイアウト再適用を行わず、デスクトップ時はチャットUI再保証のみ実施するよう修正
- 2026-03-01 03:24:31 JST
  - 起動直後の表示安定化ガードを追加し、数秒間はデスクトップモード/チャットUI（履歴・入力欄・送信/音声ボタン）を再確認して欠落時に自動復旧するよう修正
  - 入力欄を下部ドック（固定高さ）として再実装し、初期表示や再レイアウト後でも入力欄が消えないように改善
  - `AI_BACKEND=auto` で起動した場合も、実際に選択されたバックエンド/モデルを起動ポップアップで表示し、5秒後にデスクトップ画面へ戻る挙動を追加
- 2026-03-01 03:16:25 JST
  - 起動時フローを修正し、初回表示から `デスクトップモード` でチャット履歴・入力欄・送信ボタン・音声ボタンを表示するように改善
  - チャット履歴ウィジェットと入力ウィジェットの存在チェック/再構築処理を追加し、欠落時でも自動復旧するように修正
  - モデル自動選択時に非ブロッキングのポップアップを表示し、選択モデル情報を表示した後に5秒でデスクトップ画面へ復帰する処理を追加
  - `AliceApp.py` から `module/window_module.py` へ自動選択モデル情報を連携し、起動時に通知できるように実装
  - `LOCAL_MODEL_REPO` / `LOCAL_MODEL_FILE` の既定値を `auto` 化し、PCスペックに応じたローカルモデル自動選択・DLを標準動作に変更
- 2026-03-01 02:58:18 JST
  - 上記対応として、ローカル学習済みモデル（GGUF）を Hugging Face から自動DLして対話に利用する実装を履歴へ追記
  - `module/local_llm_loader_module.py`（DL/ロード）と `src/AI/local_heart.py`（ローカル推論）を追加した内容を記録
  - `AI_BACKEND`（auto/gemini/local）と Local モデル設定項目（Repo/File/Dir/Token 等）の追加内容を記録
  - 設定画面の Local タブ追加・設定保存時のローダーリセット・READMEのローカルモデル手順追加を記録
- 2026-03-01 02:55:01 JST
  - ローカル学習済みモデル（GGUF）をWeb（Hugging Face）から自動DLして利用する機能を追加
  - `AI_BACKEND`（auto/gemini/local）を追加し、Gemini失敗時のローカルLLMフォールバックを実装
  - Local LLM 推論クラス (`src/AI/local_heart.py`) を追加し、既存チャットUIからそのまま対話可能に拡張
  - 設定画面に `AIバックエンド` と `Local` タブを追加（Repo/File/Dir/Context/Token等を編集可能）
  - 設定保存時に Gemini/Local ローダーのキャッシュをリセットする処理を追加
- 2026-03-01 02:46:30 JST
  - 起動時にデスクトップモードを強制適用し、初回表示からチャット欄が見えるように修正
  - デスクトップモード復帰時にチャットペイン分割を再補正する処理を追加（入力欄欠落の再発防止）
  - 入力欄の存在チェックと再構築ガードを追加し、ユーザー入力UIを常に利用可能に修正
  - 設定画面の AIモデル をコンボ選択化（主要 Gemini Flash 系モデルを選択可能）
  - AI接続失敗時に利用可能モデルを自動選択して再接続を試行する起動処理を追加
  - AI未接続時にチャット上へ設定案内メッセージを表示するよう改善
- 2026-03-01 01:54:48 JST
  - キャラクターモード切替を実装（表示メニューから Desktop / Character を切替可能）
  - ログフォルダを開く処理をクロスプラットフォーム化（Windows / macOS / Linux / Android / iOS フォールバック）
  - レイヤーのドラッグ移動操作を実装（合成プレビュー上で左ドラッグ）
  - 音声キューイングを実装（VOICEVOX 発話を順番再生、stopで未再生キューもクリア）
  - ブロック方式（全セル一括処理）で未設定セルにプレースホルダー画像を自動補完
